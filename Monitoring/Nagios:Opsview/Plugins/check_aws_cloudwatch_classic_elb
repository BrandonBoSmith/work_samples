#!/usr/bin/env python3
##############################################################################
'''
Description:	Opsview/Nagios plugin used to monitor AWS Classic Load 
                Balancers.  check_aws_cloudwatch does not handle empty
                output from cloudwatch very well and empty values show up
                as unknown so that is why this plugin is being written.

Requirements:	AWS Item            Opsview Variable
                Access Key          %AWS_CLOUDWATCH_AUTHENTICATION:2%
                Secret Key          %AWS_CLOUDWATCH_AUTHENTICATION:3%
                Load Balancer Name  %AWS_ELB_LOAD_BALANCER_NAME%
                    Example 'Name=LoadBalancer,Value=app/lbname/1234566
                    Value can be obtained from CloudWatch -> AWS/ApplicationELB
                Metric Name         
Created:	    2019-09-12
Author:		    Bo Smith (bo@bosmith.tech)
'''
##############################################################################
import argparse
import boto3
import pprint
import sys
from datetime import datetime, timedelta

ok = 0
warn = 1
crit = 2
unknown = 3


# Get arguments
##############################################################################
def get_args():
    # Put arg choices in variables so we can present them more cleanly in our
    # --help output
    metric_choices = ['EstimatedALBActiveConnectionCount',
                      'EstimatedALBNewConnectionCount',
                      'EstimatedProcessedBytes',
                      'EstimatedALBConsumedLCUs',
                      'UnHealthyHostCount',
                      'HealthyHostCount',
                      'Latency',
                      'RequestCount',
                      'HTTPCode_ELB_5XX',
                      'HTTPCode_Backend_5XX',
                      'HTTPCode_Backend_4XX',
                      'HTTPCode_Backend_2XX',
                      'BackendConnectionErrors',
                      'SurgeQueueLength']

    statistic_choices = ['SampleCount', 'Average', 'Sum', 'Minimum',
                         'Maximum']

    # Give me all your args and no one gets hurt
    parser = argparse.ArgumentParser(
        usage='%(prog)s [-H] [-u] [-p]',
        description='Opsview plugin to monitor AWS Application ELB')
    parser.add_argument('-A', '--accesskey', action='store', required=True,
                        help='Access key', metavar='')
    parser.add_argument('-S', '--secretkey', action='store', required=True,
                        help='Secret Key', metavar='')
    parser.add_argument('-m', '--metric', action='store', required=True,
                        help='Metric to retrieve.  Valid options are ' +
                        ', '.join(metric_choices),
                        choices=metric_choices, metavar='')
    parser.add_argument('-n', '--name', action='store', required=True,
                        help='Name of the load balancer', metavar='')
    parser.add_argument('-a', '--availabilityzone', action='store',
                        required=False, metavar='',
                        help='Availability Zone to get metrics for')
    parser.add_argument('-s', '--statistics', action='store', required=True,
                        choices=statistic_choices,
                        help='Cloudwatch statistic. Valid choices are ' +
                        ', '.join(statistic_choices),
                        metavar='')
    parser.add_argument('-r', '--region', action='store', required=False,
                        help='AWS Region', metavar='')
    parser.add_argument('-w', '--warning', action='store', required=False,
                        type=float, help='Warning threshold in percentage',
                        metavar='')
    parser.add_argument('-c', '--critical', action='store', required=False,
                        type=float, help='Critical threshold in percentage',
                        metavar='')
    parser.add_argument('--format_float', action='store', required=False,
                        type=int,
                        help='If set, formats the output to the decimal \
                        place number defined',
                        metavar='')
    parser.add_argument('--starttime', action='store', required=False,
                        type=int, default=300,
                        help='Start time for the cloudwatch query defined \
                        as "X seconds ago" (default 300)',
                        metavar='')
    args = parser.parse_args()
    return(args)


# Get Cloudwatch Metrics
##############################################################################
def get_metrics(args, dimensions):
    # Pull the metric data
    endtime = datetime.now()
    starttime = endtime - timedelta(seconds=args.starttime)
    try:
        client = boto3.client('cloudwatch',
                              aws_access_key_id=args.accesskey,
                              aws_secret_access_key=args.secretkey,
                              region_name=args.region)
    except Exception as err:
        send_unknown('ERROR - '+str(err))
    try:
        response = client.get_metric_statistics(Dimensions=dimensions,
                                                MetricName=args.metric,
                                                Namespace='AWS/ELB',
                                                StartTime=starttime,
                                                EndTime=endtime,
                                                Period=300,
                                                Statistics=[args.statistics])
    except Exception as err:
        send_unknown('ERROR - '+str(err))
    return(response)


# Process Metrics Greater Than
##############################################################################
def process_metrics_gt(metrics, args):
    # Checks if metrics are greater than threshold
    # At this point we should have data to test for thresholds if
    # thresholds are applied
    # If we want both Critical and Warning alerts
    if args.format_float:
        ft = '.'+str(args.format_float)+'f'
        message = args.metric+' is '+str(format(metrics[args.statistics], ft))
        message += ' | '+args.metric.lower()
        message += '='+str(format(metrics[args.statistics], ft))
    else:
        message = args.metric+' is '+str(metrics[args.statistics])
        message += ' | '+args.metric.lower()+'='+str(metrics[args.statistics])
    if args.critical and args.warning:
        if metrics[args.statistics] >= args.critical:
            send_critical(message)
        elif metrics[args.statistics] >= args.warning:
            send_warning(message)
        else:
            send_ok(message)
    # If we just want critical alerts
    elif args.critical:
        if metrics[args.statistics] >= args.critical:
            send_critical(message)
        else:
            send_ok(message)
    # If we just want warning alerts
    elif args.warning:
        if metrics[args.statistics] >= args.warning:
            send_warning(message)
        else:
            send_ok(message)
    # If we only want to gather the metrics and not alert
    else:
        send_ok(message)


# Process Metrics Less Than
##############################################################################
def process_metrics_lt(metrics, args):
    # Checks if metrics are less than threshold
    # At this point we should have data to test for thresholds if
    # thresholds are applied
    # If we want both Critical and Warning alerts
    if args.format_float:
        ft = '.'+str(args.format_float)+'f'
        message = args.metric+' is '+str(format(metrics[args.statistics], ft))
        message += ' | '+args.metric.lower()
        message += '='+str(format(metrics[args.statistics], ft))
    else:
        message = args.metric+' is '+str(metrics[args.statistics])
        message += ' | '+args.metric.lower()+'='+str(metrics[args.statistics])
    if args.critical and args.warning:
        if metrics[args.statistics] <= args.critical:
            send_critical(message)
        elif metrics[args.statistics] <= args.warning:
            send_warning(message)
        else:
            send_ok(message)
    # If we just want critical alerts
    elif args.critical:
        if metrics[args.statistics] <= args.critical:
            send_critical(message)
        else:
            send_ok(message)
    # If we just want warning alerts
    elif args.warning:
        if metrics[args.statistics] <= args.warning:
            send_warning(message)
        else:
            send_ok(message)
    # If we only want to gather the metrics and not alert
    else:
        send_ok(message)


# Metric ActiveConnectionCount
##############################################################################
def metric_activeconnectioncount(args):
    dimensions = [{'Name': 'LoadBalancerName', 'Value': args.name}]
    data = get_metrics(args, dimensions)
    try:
        metrics = data['Datapoints'][0]
    except:
        if data['ResponseMetadata']['HTTPStatusCode'] == 200:
            metrics = {}
            metrics[args.statistics] = float(0.0)
        else:
            send_unknown('No datapoints returned')
    process_metrics_gt(metrics, args)


# Metric Latency
##############################################################################
def metric_latency(args):
    dimensions = [{'Name': 'LoadBalancerName', 'Value': args.name}]
    data = get_metrics(args, dimensions)
    try:
        metrics = data['Datapoints'][0]
    except:
        if data['ResponseMetadata']['HTTPStatusCode'] == 200:
            metrics = {}
            metrics[args.statistics] = float(0.0)
        else:
            send_unknown('No datapoints returned')
    process_metrics_gt(metrics, args)


# Metric EstimatedALBNewConnectionCount
##############################################################################
def metric_newconnectioncount(args):
    dimensions = [{'Name': 'LoadBalancerName', 'Value': args.name}]
    data = get_metrics(args, dimensions)
    try:
        metrics = data['Datapoints'][0]
    except:
        if data['ResponseMetadata']['HTTPStatusCode'] == 200:
            metrics = {}
            metrics[args.statistics] = float(0.0)
        else:
            send_unknown('No datapoints returned')
    process_metrics_gt(metrics, args)


# Metric RequestCount
##############################################################################
def metric_requestcount(args):
    dimensions = [{'Name': 'LoadBalancerName', 'Value': args.name}]
    data = get_metrics(args, dimensions)
    try:
        metrics = data['Datapoints'][0]
    except:
        if data['ResponseMetadata']['HTTPStatusCode'] == 200:
            metrics = {}
            metrics[args.statistics] = float(0.0)
        else:
            send_unknown('No datapoints returned')
    process_metrics_gt(metrics, args)


# Metric EstimatedALBConsumedLCUs
##############################################################################
def metric_consumedlcus(args):
    dimensions = [{'Name': 'LoadBalancerName', 'Value': args.name}]
    data = get_metrics(args, dimensions)
    try:
        # This metrics seems to report whenver the F*** it feels like it
        # so we handle this by adding --starttime in the args large enough
        # to return a big data set, then here we sort it and take the last
        # item in the sorted list which is then the most recent
        metrics = data['Datapoints']
        metrics = sorted(metrics, key=lambda i: i['Timestamp'])
        metrics = metrics[-1]
    except:
        if data['ResponseMetadata']['HTTPStatusCode'] == 200:
            metrics = {}
            metrics[args.statistics] = float(0.0)
        else:
            send_unknown('No datapoints returned')
    process_metrics_gt(metrics, args)


# Metric ProcessedBytes
##############################################################################
def metric_processedbytes(args):
    dimensions = [{'Name': 'LoadBalancerName', 'Value': args.name}]
    data = get_metrics(args, dimensions)
    try:
        metrics = data['Datapoints'][0]
    except:
        if data['ResponseMetadata']['HTTPStatusCode'] == 200:
            metrics = {}
            metrics[args.statistics] = float(0.0)
        else:
            send_unknown('No datapoints returned')
    process_metrics_gt(metrics, args)


# Metric BackendConnectionErrors
##############################################################################
def metric_backendconnectionerrors(args):
    dimensions = [{'Name': 'LoadBalancerName', 'Value': args.name}]
    data = get_metrics(args, dimensions)
    try:
        metrics = data['Datapoints'][0]
    except:
        if data['ResponseMetadata']['HTTPStatusCode'] == 200:
            metrics = {}
            metrics[args.statistics] = float(0.0)
        else:
            send_unknown('No datapoints returned')
    process_metrics_gt(metrics, args)


# Metric SurgeQueueLength
##############################################################################
def metric_sergequeuelength(args):
    dimensions = [{'Name': 'LoadBalancerName', 'Value': args.name}]
    data = get_metrics(args, dimensions)
    try:
        metrics = data['Datapoints'][0]
    except:
        if data['ResponseMetadata']['HTTPStatusCode'] == 200:
            metrics = {}
            metrics[args.statistics] = float(0.0)
        else:
            send_unknown('No datapoints returned')
    process_metrics_gt(metrics, args)


# Metric HealthyHostCount
##############################################################################
def metric_healthyhostcount(args):
    dimensions = [{'Name': 'LoadBalancerName', 'Value': args.name}]
    data = get_metrics(args, dimensions)
    try:
        metrics = data['Datapoints'][0]
    except:
        if data['ResponseMetadata']['HTTPStatusCode'] == 200:
            metrics = {}
            metrics[args.statistics] = float(0.0)
        else:
            send_unknown('No datapoints returned')
    process_metrics_lt(metrics, args)


# Metric UnHealthyHostCount
##############################################################################
def metric_unhealthyhostcount(args):
    dimensions = [{'Name': 'LoadBalancerName', 'Value': args.name}]
    data = get_metrics(args, dimensions)
    try:
        metrics = data['Datapoints'][0]
    except:
        if data['ResponseMetadata']['HTTPStatusCode'] == 200:
            metrics = {}
            metrics[args.statistics] = float(0.0)
        else:
            send_unknown('No datapoints returned')
    process_metrics_gt(metrics, args)


# Metric HTTPCode_Backend_5XX
##############################################################################
def metric_httpcode_backend_5xx(args):
    dimensions = [{'Name': 'LoadBalancerName', 'Value': args.name}]
    data = get_metrics(args, dimensions)
    try:
        metrics = data['Datapoints'][0]
    except:
        if data['ResponseMetadata']['HTTPStatusCode'] == 200:
            metrics = {}
            metrics[args.statistics] = float(0.0)
        else:
            send_unknown('No datapoints returned')
    process_metrics_gt(metrics, args)


# Metric HTTPCode_ELB_5XX
##############################################################################
def metric_httpcode_elb_5xx(args):
    dimensions = [{'Name': 'LoadBalancerName', 'Value': args.name}]
    data = get_metrics(args, dimensions)
    try:
        metrics = data['Datapoints'][0]
    except:
        if data['ResponseMetadata']['HTTPStatusCode'] == 200:
            metrics = {}
            metrics[args.statistics] = float(0.0)
        else:
            send_unknown('No datapoints returned')
    process_metrics_gt(metrics, args)


# Metric HTTPCode_Backend_4XX
##############################################################################
def metric_httpcode_backend_4xx(args):
    dimensions = [{'Name': 'LoadBalancerName', 'Value': args.name}]
    data = get_metrics(args, dimensions)
    try:
        metrics = data['Datapoints'][0]
    except:
        if data['ResponseMetadata']['HTTPStatusCode'] == 200:
            metrics = {}
            metrics[args.statistics] = float(0.0)
        else:
            send_unknown('No datapoints returned')
    process_metrics_gt(metrics, args)


# Metric HTTPCode_Backend_2XX
##############################################################################
def metric_httpcode_backend_2xx(args):
    dimensions = [{'Name': 'LoadBalancerName', 'Value': args.name}]
    data = get_metrics(args, dimensions)
    try:
        metrics = data['Datapoints'][0]
    except:
        if data['ResponseMetadata']['HTTPStatusCode'] == 200:
            metrics = {}
            metrics[args.statistics] = float(0.0)
        else:
            send_unknown('No datapoints returned')
    process_metrics_gt(metrics, args)


# Alert Functions
##############################################################################
def send_warning(message):
    print('WARNING - '+message)
    sys.exit(warn)


def send_critical(message):
    print('CRITICAL - '+message)
    sys.exit(crit)


def send_ok(message):
    print('OK - '+message)
    sys.exit(ok)


def send_unknown(message):
    print('UNKNOWN - '+message)
    sys.exit(unknown)


# Git-r-done!
##############################################################################
def main():
    args = get_args()
    if args.metric == 'EstimatedALBActiveConnectionCount':
        metric_activeconnectioncount(args)
    elif args.metric == 'RequestCount':
        metric_requestcount(args)
    elif args.metric == 'Latency':
        metric_latency(args)
    elif args.metric == 'EstimatedALBConsumedLCUs':
        metric_consumedlcus(args)
    elif args.metric == 'EstimatedProcessedBytes':
        metric_processedbytes(args)
    elif args.metric == 'EstimatedALBNewConnectionCount':
        metric_newconnectioncount(args)
    elif args.metric == 'BackendConnectionErrors':
        metric_backendconnectionerrors(args)
    elif args.metric == 'SurgeQueueLength':
        metric_sergequeuelength(args)
    elif args.metric == 'HealthyHostCount':
        metric_healthyhostcount(args)
    elif args.metric == 'UnHealthyHostCount':
        metric_unhealthyhostcount(args)
    elif args.metric == 'HTTPCode_ELB_5XX':
        metric_httpcode_elb_5xx(args)
    elif args.metric == 'HTTPCode_Backend_5XX':
        metric_httpcode_backend_5xx(args)
    elif args.metric == 'HTTPCode_Backend_4XX':
        metric_httpcode_backend_4xx(args)
    elif args.metric == 'HTTPCode_Backend_2XX':
        metric_httpcode_backend_2xx(args)
    else:
        send_unknown('unsupported metric')


if __name__ == "__main__":
    main()
