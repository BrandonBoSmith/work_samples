#!/usr/bin/env python3
##############################################################################
'''
Description:	Opsview/Nagios plugin used to monitor AWS Network Load 
                Balancers.  check_aws_cloudwatch does not handle empty
                output from cloudwatch very well and empty values show up
                as unknown so that is why this plugin is being written.

Requirements:	AWS Item            Opsview Variable
                Access Key          %AWS_CLOUDWATCH_AUTHENTICATION:2%
                Secret Key          %AWS_CLOUDWATCH_AUTHENTICATION:3%
                Load Balancer Name  %AWS_ELB_LOAD_BALANCER_NAME%
                    Example 'Name=LoadBalancer,Value=app/lbname/1234566
                    Value can be obtained from CloudWatch -> ALL/NetworkELB
                Metric Name         
Created:	    2019-09-12
Author:		    Bo Smith (bo@bosmith.tech)
'''
##############################################################################
import argparse
import boto3
import pprint
import sys
from datetime import datetime, timedelta

ok = 0
warn = 1
crit = 2
unknown = 3


# Get arguments
##############################################################################
def get_args():
    # Put arg choices in variables so we can present them more cleanly in our
    # --help output
    metric_choices = ['ActiveFlowCount',
                      'NewFlowCount',
                      'ConsumedLCUs',
                      'TCP_ELB_Reset_Count',
                      'TCP_Client_Reset_Count',
                      'TCP_Target_Reset_Count',
                      'ProcessedBytes']

    statistic_choices = ['SampleCount', 'Average', 'Sum', 'Minimum',
                         'Maximum']

    # Give me all your args and no one gets hurt
    parser = argparse.ArgumentParser(
        usage='%(prog)s [-H] [-u] [-p]',
        description='Opsview plugin to monitor AWS Application ELB')
    parser.add_argument('-A', '--accesskey', action='store', required=True,
                        help='Access key', metavar='')
    parser.add_argument('-S', '--secretkey', action='store', required=True,
                        help='Secret Key', metavar='')
    parser.add_argument('-m', '--metric', action='store', required=True,
                        help='Metric to retrieve.  Valid options are ' +
                        ', '.join(metric_choices),
                        choices=metric_choices, metavar='')
    parser.add_argument('-n', '--name', action='store', required=True,
                        help='Name of the load balancer', metavar='')
    parser.add_argument('-a', '--availabilityzone', action='store',
                        required=False, metavar='',
                        help='Availability Zone to get metrics for')
    parser.add_argument('-s', '--statistics', action='store', required=True,
                        choices=statistic_choices,
                        help='Cloudwatch statistic. Valid choices are ' +
                        ', '.join(statistic_choices),
                        metavar='')
    parser.add_argument('-r', '--region', action='store', required=False,
                        help='AWS Region', metavar='')
    parser.add_argument('-w', '--warning', action='store', required=False,
                        type=float, help='Warning threshold in percentage',
                        metavar='')
    parser.add_argument('-c', '--critical', action='store', required=False,
                        type=float, help='Critical threshold in percentage',
                        metavar='')
    parser.add_argument('--format_float', action='store', required=False,
                        type=int,
                        help='If set, formats the output to the decimal \
                        place number defined',
                        metavar='')
    parser.add_argument('--starttime', action='store', required=False,
                        type=int, default=300,
                        help='Start time for the cloudwatch query defined \
                        as "X seconds ago" (default 300)',
                        metavar='')
    args = parser.parse_args()
    return(args)


# Get Cloudwatch Metrics
##############################################################################
def get_metrics(args, dimensions):
    # Pull the metric data
    endtime = datetime.now()
    starttime = endtime - timedelta(seconds=args.starttime)
    try:
        client = boto3.client('cloudwatch',
                              aws_access_key_id=args.accesskey,
                              aws_secret_access_key=args.secretkey,
                              region_name=args.region)
    except Exception as err:
        send_unknown('ERROR - '+str(err))
    try:
        response = client.get_metric_statistics(Dimensions=dimensions,
                                                MetricName=args.metric,
                                                Namespace='AWS/NetworkELB',
                                                StartTime=starttime,
                                                EndTime=endtime,
                                                Period=300,
                                                Statistics=[args.statistics])
    except Exception as err:
        send_unknown('ERROR - '+str(err))
    return(response)


# Process Metrics Greater Than
##############################################################################
def process_metrics_gt(metrics, args):
    # Checks if metrics are greater than threshold
    # At this point we should have data to test for thresholds if
    # thresholds are applied
    # If we want both Critical and Warning alerts
    if args.format_float:
        ft = '.'+str(args.format_float)+'f'
        message = args.metric+' is '+str(format(metrics[args.statistics], ft))
        message += ' | '+args.metric.lower()
        message += '='+str(format(metrics[args.statistics], ft))
    else:
        message = args.metric+' is '+str(metrics[args.statistics])
        message += ' | '+args.metric.lower()+'='+str(metrics[args.statistics])
    if args.critical and args.warning:
        if metrics[args.statistics] >= args.critical:
            send_critical(message)
        elif metrics[args.statistics] >= args.warning:
            send_warning(message)
        else:
            send_ok(message)
    # If we just want critical alerts
    elif args.critical:
        if metrics[args.statistics] >= args.critical:
            send_critical(message)
        else:
            send_ok(message)
    # If we just want warning alerts
    elif args.warning:
        if metrics[args.statistics] >= args.warning:
            send_warning(message)
        else:
            send_ok(message)
    # If we only want to gather the metrics and not alert
    else:
        send_ok(message)


# Process Metrics Less Than
##############################################################################
def process_metrics_lt(metrics, args):
    # Checks if metrics are less than threshold
    # At this point we should have data to test for thresholds if
    # thresholds are applied
    # If we want both Critical and Warning alerts
    if args.format_float:
        ft = '.'+str(args.format_float)+'f'
        message = args.metric+' is '+str(format(metrics[args.statistics], ft))
        message += ' | '+args.metric.lower()
        message += '='+str(format(metrics[args.statistics], ft))
    else:
        message = args.metric+' is '+str(metrics[args.statistics])
        message += ' | '+args.metric.lower()+'='+str(metrics[args.statistics])
    if args.critical and args.warning:
        if metrics[args.statistics] <= args.critical:
            send_critical(message)
        elif metrics[args.statistics] <= args.warning:
            send_warning(message)
        else:
            send_ok(message)
    # If we just want critical alerts
    elif args.critical:
        if metrics[args.statistics] <= args.critical:
            send_critical(message)
        else:
            send_ok(message)
    # If we just want warning alerts
    elif args.warning:
        if metrics[args.statistics] <= args.warning:
            send_warning(message)
        else:
            send_ok(message)
    # If we only want to gather the metrics and not alert
    else:
        send_ok(message)


# Metric ActiveFlowCount
##############################################################################
def metric_activeflowcount(args):
    dimensions = [{'Name': 'LoadBalancer', 'Value': args.name}]
    data = get_metrics(args, dimensions)
    try:
        metrics = data['Datapoints'][0]
    except:
        if data['ResponseMetadata']['HTTPStatusCode'] == 200:
            metrics = {}
            metrics[args.statistics] = float(0.0)
        else:
            send_unknown('No datapoints returned')
    process_metrics_gt(metrics, args)


# Metric NewFlowCount
##############################################################################
def metric_newflowcount(args):
    dimensions = [{'Name': 'LoadBalancer', 'Value': args.name}]
    data = get_metrics(args, dimensions)
    try:
        metrics = data['Datapoints'][0]
    except:
        if data['ResponseMetadata']['HTTPStatusCode'] == 200:
            metrics = {}
            metrics[args.statistics] = float(0.0)
        else:
            send_unknown('No datapoints returned')
    process_metrics_gt(metrics, args)


# Metric ConsumedLCUs
##############################################################################
def metric_consumedlcus(args):
    dimensions = [{'Name': 'LoadBalancer', 'Value': args.name}]
    data = get_metrics(args, dimensions)
    try:
        # This metrics seems to report whenver the F*** it feels like it
        # so we handle this by adding --starttime in the args large enough
        # to return a big data set, then here we sort it and take the last
        # item in the sorted list which is then the most recent
        metrics = data['Datapoints']
        metrics = sorted(metrics, key=lambda i: i['Timestamp'])
        metrics = metrics[-1]
    except:
        if data['ResponseMetadata']['HTTPStatusCode'] == 200:
            metrics = {}
            metrics[args.statistics] = float(0.0)
        else:
            send_unknown('No datapoints returned')
    process_metrics_gt(metrics, args)


# Metric TCP_ELB_Reset_Count
##############################################################################
def metric_tcp_elb_reset_count(args):
    dimensions = [{'Name': 'LoadBalancer', 'Value': args.name}]
    data = get_metrics(args, dimensions)
    try:
        metrics = data['Datapoints'][0]
    except:
        if data['ResponseMetadata']['HTTPStatusCode'] == 200:
            metrics = {}
            metrics[args.statistics] = float(0.0)
        else:
            send_unknown('No datapoints returned')
    process_metrics_gt(metrics, args)


# Metric TCP_Client_Reset_Count
##############################################################################
def metric_tcp_client_reset_count(args):
    dimensions = [{'Name': 'LoadBalancer', 'Value': args.name}]
    data = get_metrics(args, dimensions)
    try:
        metrics = data['Datapoints'][0]
    except:
        if data['ResponseMetadata']['HTTPStatusCode'] == 200:
            metrics = {}
            metrics[args.statistics] = float(0.0)
        else:
            send_unknown('No datapoints returned')
    process_metrics_gt(metrics, args)


# Metric TCP_Target_Reset_Count
##############################################################################
def metric_tcp_target_reset_count(args):
    dimensions = [{'Name': 'LoadBalancer', 'Value': args.name}]
    data = get_metrics(args, dimensions)
    try:
        metrics = data['Datapoints'][0]
    except:
        if data['ResponseMetadata']['HTTPStatusCode'] == 200:
            metrics = {}
            metrics[args.statistics] = float(0.0)
        else:
            send_unknown('No datapoints returned')
    process_metrics_gt(metrics, args)


# Metric ProcessedBytes
##############################################################################
def metric_processedbytes(args):
    dimensions = [{'Name': 'LoadBalancer', 'Value': args.name}]
    data = get_metrics(args, dimensions)
    try:
        metrics = data['Datapoints'][0]
    except:
        if data['ResponseMetadata']['HTTPStatusCode'] == 200:
            metrics = {}
            metrics[args.statistics] = float(0.0)
        else:
            send_unknown('No datapoints returned')
    process_metrics_gt(metrics, args)


# Alert Functions
##############################################################################
def send_warning(message):
    print('WARNING - '+message)
    sys.exit(warn)


def send_critical(message):
    print('CRITICAL - '+message)
    sys.exit(crit)


def send_ok(message):
    print('OK - '+message)
    sys.exit(ok)


def send_unknown(message):
    print('UNKNOWN - '+message)
    sys.exit(unknown)


# Git-r-done!
##############################################################################
def main():
    args = get_args()
    if args.metric == 'ActiveFlowCount':
        metric_activeflowcount(args)
    elif args.metric == 'NewFlowCount':
        metric_newflowcount(args)
    elif args.metric == 'ConsumedLCUs':
        metric_consumedlcus(args)
    elif args.metric == 'TCP_ELB_Reset_Count':
        metric_tcp_elb_reset_count(args)
    elif args.metric == 'TCP_Client_Reset_Count':
        metric_tcp_client_reset_count(args)
    elif args.metric == 'TCP_Target_Reset_Count':
        metric_tcp_target_reset_count(args)
    elif args.metric == 'ProcessedBytes':
        metric_processedbytes(args)
    else:
        send_unknown('unsupported metric')


if __name__ == "__main__":
    main()
